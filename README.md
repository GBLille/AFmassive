![header](imgs/header.png)

# MassiveFold

Table of contents
=================

  * [Setup](#setup)
  * [Added parameters](#added-parameters)
  * [Dropout](#dropout)
  * [Usage](#usage)
    * [Examples](#example)
  * [MassiveFold in parallel](#running-massivefold-in-parallel)
      * [Setup](#setup-1)
      * [Header Building](#jobfiles-header-building)
      * [Usage](#usage-1)
      * [Inference workflow](#inference-workflow)
  * [Plots](#mf_plots-output-representation)


This AlphaFold version aims at massively expanding the sampling of structure predictions following Björn Wallner's 
AFsample version of AlphaFold (https://github.com/bjornwallner/alphafoldv2.2.0/)  and to provide some optimizations in the computing.  
In particular, it optimizes the parallellization of the computing, generating automatically batches of predictions that can be run in parallel. 
The size of these batches is automatically calculated running a first calibrating run or set manually. All the results are then gathered 
in a same folder and a final global ranking is performed on all the produced structures.
The optimizations and the parameters added to the genuine DeepMind's AlphaFold are described below.

MassiveFold is an extended version of DeepMind's AlphaFold v2.3.2: https://github.com/deepmind/alphafold

# Setup
The setup is the same as the one for AlphaFold v2.3 except that this repository has to be used instead of the DeepMind's one.  
We use an installation based on conda. You can install it following these steps https://github.com/kalininalab/alphafold_non_docker
or using the conda environment file that we provide (env.yml). In this last case, don't forget to apply the OpenMM patch and 
to add the chemical properties to the common folder.

```
conda create env -f env.yml
conda activate massivefold-1.1.0
cd ${CONDA_PREFIX}/lib/python3.8/site-packages/
wget -N https://raw.githubusercontent.com/GBLille/MassiveFold/MFv1.1.0/docker/openmm.patch
patch -p0 -N < openmm.patch
cd ${CONDA_PREFIX}/lib/python3.8/site-packages/alphafold/common/
wget -N https://git.scicore.unibas.ch/schwede/openstructure/-/raw/7102c63615b64735c4941278d92b554ec94415f8/modules/mol/alg/src/stereo_chemical_props.txt
```

However, v1 and v2 neural network (NN) model parameters have to be present in the *param* folder and should contain the 
version number in their name.\
Therefore, the list of NN model parameters in the folder should be as follows:

params_model_1_multimer_v1.npz  
params_model_1_multimer_v2.npz  
params_model_1_multimer_v3.npz  
params_model_1.npz  
params_model_1_ptm.npz  
params_model_2_multimer_v1.npz  
params_model_2_multimer_v2.npz  
params_model_2_multimer_v3.npz  
params_model_2.npz  
params_model_2_ptm.npz  
params_model_3_multimer_v1.npz  
params_model_3_multimer_v2.npz  
params_model_3_multimer_v3.npz  
params_model_3.npz  
params_model_3_ptm.npz  
params_model_4_multimer_v1.npz  
params_model_4_multimer_v2.npz  
params_model_4_multimer_v3.npz  
params_model_4.npz  
params_model_4_ptm.npz  
params_model_5_multimer_v1.npz  
params_model_5_multimer_v2.npz  
params_model_5_multimer_v3.npz  
params_model_5.npz  
params_model_5_ptm.npz  

Parameters for monomer and multimer v3 are available here: https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar  
Parameters for monomer and multimer v2 are available here: https://storage.googleapis.com/alphafold/alphafold_params_2022-03-02.tar  
Parameters for monomer and multimer v1 are available here: https://storage.googleapis.com/alphafold/alphafold_params_2021-10-27.tar  

# Added parameters
This is the list of the parameters added to AlphaFold 2.3.2 and their description, also accessible through the --help option.

  **--alignments_only**: whether to generate only alignments. Only alignments will be generated by the data pipeline, the modelling will not be performed
    (default: 'false')  
  **--dropout**: turn on drop out during inference to get more diversity
    (default: 'false')  
  **--dropout_structure_module**: activates dropout or not during inference  
  &nbsp;&nbsp;&nbsp;&nbsp; in the structure module to get more diversity (default: 'false')  
  **--dropout_rates_filename**: provide dropout rates at inference from a json file.
  If None, default rates are used, if "dropout" is True.  
  **--max_recycles**: maximum number of recycles to run
    (default: '20')
    (an integer)  
  **--early_stop_tolerance**: early stopping threshold for recycling
    (default: '0.5')
    (a number)  
  **--bfd_max_hits**: max hits in BFD/uniref MSA
    (default: '100000')
    (an integer)  
  **--mgnify_max_hits**: max hits in mgnify MSA
    (default: '501')
    (an integer)  
 **--uniprot_max_hits**: max hits in uniprot MSA
    (default: '50000')
    (an integer)  
  **--uniref_max_hits**: max hits in uniref MSA
    (default: '10000')
    (an integer)  
  **--model_preset**: <monomer|monomer_casp14|monomer_ptm|multimer>:  
  &nbsp;&nbsp;&nbsp;&nbsp; choose preset model configuration - monomer model,  
  &nbsp;&nbsp;&nbsp;&nbsp; monomer model with extra ensembling, monomer model with pTM head, or  
  &nbsp;&nbsp;&nbsp;&nbsp; multimer model; "multimer" computes the 3 versions of multimer models by default  
  &nbsp;&nbsp;&nbsp;&nbsp; if models are not specified in the *--models_to_use* parameter  
  &nbsp;&nbsp;&nbsp;&nbsp; (default: 'monomer')  
  **--models_to_use**: specify which models in *--model_preset* that should be run, each model should be formated,  
  &nbsp;&nbsp;&nbsp;&nbsp; for monomer and monomer_casp14 as model_X, with X the number of the model,  
  &nbsp;&nbsp;&nbsp;&nbsp; for monomer_ptm as model_X_ptm, with X the number of the model,  
  &nbsp;&nbsp;&nbsp;&nbsp; for multimer as model_X_multimer_vY with X the number of the model and Y  
  &nbsp;&nbsp;&nbsp;&nbsp; the version of the model.')  
  &nbsp;&nbsp;&nbsp;&nbsp; (a comma separated list)  
  **--start_prediction**: model to start with, can be used to parallelize jobs,  
  &nbsp;&nbsp;&nbsp;&nbsp; *e.g.* --num_predictions_per_model 20 --start_prediction 20 will only make model _20  
  &nbsp;&nbsp;&nbsp;&nbsp; *e.g.* --num_predictions_per_model 21 --start_prediction 20 will make model _20 and _21 *etc.*  
  &nbsp;&nbsp;&nbsp;&nbsp; (default: '1')  
  **--end_prediction**: index of the last predicted structure,  
&nbsp;&nbsp;&nbsp;&nbsp; also designates how many predictions (each with a different random seed) will be  
&nbsp;&nbsp;&nbsp;&nbsp; generated per model. *e.g.* if this is 2 and there are 5 models then there will be 10 predictions per input.  
&nbsp;&nbsp;&nbsp;&nbsp; Note: this FLAG works for monomer and multimer  
&nbsp;&nbsp;&nbsp;&nbsp; (default: '5')  
  **--templates**: whether to use templates or not, setting it to false is faster than filtering by date
  (default: 'true')  
  **--score_threshold_output**: only predictions with ranking confidence above this score  
  &nbsp;&nbsp;&nbsp;&nbsp; will generate pdb and pkl files, predictions below this  
  &nbsp;&nbsp;&nbsp;&nbsp; threshold will still be present in ranking_debug.json.  
  &nbsp;&nbsp;&nbsp;&nbsp; (default: '0')  
  **--max_score_stop**: stops the computing process when a suitable  
  &nbsp;&nbsp;&nbsp;&nbsp; prediction with a ranking confidence > max_score_stop has been obtained  
  &nbsp;&nbsp;&nbsp;&nbsp; (default: '1')

# Dropout
The dropout at inference can be activated with the **--dropout** parameter set to true for activating it in the Evoformer 
module and **--dropout_structure_module** set to true for activating it in the structure module.
The same dropout rates as those used by DeepMind at training are used. Here are DeepMind's architectural details 
(Jumper J et al, Nature, 2021 - Fig 3.a), annotated by Björn Wallner for CASP15 (https://predictioncenter.org/), 
that shows the various dropout rates:  

![Dropout](imgs/dropout_arch.png)

However, the **--dropout_rates_filename** parameter allows to modify these rates, providing them in a json file. 
Here is an example of the content of such a json file:
```json
{  
    "dropout_rate_msa_row_attention_with_pair_bias": 0.15,  
    "dropout_rate_msa_column_attention": 0.0,  
    "dropout_rate_msa_transition": 0.0,  
    "dropout_rate_outer_product_mean": 0.0,  
    "dropout_rate_triangle_attention_starting_node": 0.25,  
    "dropout_rate_triangle_attention_ending_node": 0.25,  
    "dropout_rate_triangle_multiplication_outgoing": 0.25,  
    "dropout_rate_triangle_multiplication_incoming": 0.25,  
    "dropout_rate_pair_transition": 0.0,  
    "dropout_rate_structure_module": 0.1  
}  
```

# Usage
## Example
By default, MassiveFold runs with the same parameters as AlphaFold2, except it uses all the versions 
of neural network model parameters for complexes and not only the ones of the last version.  

Here is an example how to run a multimer prediction with all versions of neural network model parameters, without templates,
activating dropout at inference in both Evoformer and structure module, with 100 recycles maximum and early stop tolerance 
set to 0.1 Angströms. 

```bash
python3 ./run_alphafold.py
    --fasta_paths=seq.fasta
    --output_dir=./output
    --data_dir=*path_to_set*
    --db_preset=full_dbs
    --model_preset=multimer
    --max_template_date=2023-07-11
    --use_precomputed_msas=false
    --models_to_relax=best
    --use_gpu_relax=true
    --alignments_only=false
    --dropout=true
    --dropout_structure_module=true
    --dropout_rates_filename=
    --max_recycles=100
    --early_stop_tolerance=0.1
    --bfd_max_hits=100000
    --mgnify_max_hits=501
    --uniprot_max_hits=50000
    --uniref_max_hits=10000
    --models_to_use=
    --start_prediction=1
    --end_prediction=5
    --templates=false
    --score_threshold_output=0
    --max_score_stop=1
    --uniref90_database_path=*path_to_set*
    --mgnify_database_path=*path_to_set*
    --template_mmcif_dir=*path_to_set*
    --obsolete_pdbs_path=*path_to_set*
    --bfd_database_path=*path_to_set*
    --pdb_seqres_database_path=*path_to_set*
    --uniref30_database_path=*path_to_set*
    --uniprot_database_path=*path_to_set*
```

To only use a selection of models, separate them with a comma in the ***--models_to_use*** parameter, *e.g.*:  
--models_to_use=model_3_multimer_v1,model_3_multimer_v3  

A script is also provided to relax only one structure. The pkl file of the prediction has to be given in parameters and the 
*features.pkl* file must be present in the folder. *e.g.*:
```bash
python3 run_relax_from_results_pkl.py result_model_4_multimer_v3_pred_0.pkl
```

